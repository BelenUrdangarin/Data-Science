{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BelenUrdangarin/Data-Science/blob/main/Notebook_18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAipadortrs1"
      },
      "source": [
        "\n",
        "# Programa Ingenia+ Data Science"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2Fw5rW4trs6"
      },
      "source": [
        "Recordemos que un proyecto de data science tiene varias etapas:\n",
        "\n",
        "1. Recolecci√≥n de Datos\n",
        "2. Exploraci√≥n y Procesamiento de los datos\n",
        "3. Modelado\n",
        "4. Puesta en Producci√≥n\n",
        "\n",
        "En clases anteriores, trabajamos con el dataset `StudentPerformace`. Pudimos observar el tipo de datos que teniamos y le hiciemos algunas transformaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e82i9xLWtrs8"
      },
      "source": [
        "<font size=5> üöÄ üë©üèΩ‚Äçüíª Machine Learning: Aprendizaje Supervisado üì£</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq0OfMBEtrs8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.cm as cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIm3SGfUtrtF"
      },
      "outputs": [],
      "source": [
        "# Importamos la librearia para separar el dataset.\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oSXXy4strtG"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "p5qRa8V3CwWQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrABtqLAtrtG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qh9R97VduC1I"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5INo2AI_trs_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "4407e5ad-4a5d-444f-92eb-9a4f491b1665"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'estudiantes_limpio.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-4229089941.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Leemos nuevamente los datos de los estudiantes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'estudiantes_limpio.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'estudiantes_limpio.csv'"
          ]
        }
      ],
      "source": [
        "# Leemos nuevamente los datos de los estudiantes\n",
        "students = pd.read_csv('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIJoXs9btrtC"
      },
      "outputs": [],
      "source": [
        "students['puntaje_final'] = (students['math score'] + students['reading score'] + students['writing score']) / 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYW1nWOQtrtH"
      },
      "source": [
        "## Evaluaci√≥n del modelo de regresi√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n26RPfDktrtD"
      },
      "outputs": [],
      "source": [
        "# Elimino aquellas variables que no quiero incluir en el modelo y las guardo en x.\n",
        "x = students.drop(['math score', 'reading score', 'writing score', 'puntaje_final'],\n",
        "                  axis=1) #la variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBf0JdxUtrtE"
      },
      "outputs": [],
      "source": [
        "# Ahora selecciono las etiquetas y las guardo en y.\n",
        "y = students['puntaje_final'] #y lo que quiero que adivine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ewo1kUBtrtE"
      },
      "outputs": [],
      "source": [
        "x, y = np.array(x), np.array(y) #se pasa a array porque consume menos recursos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdXer8lCtrtF"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2,\n",
        "                                                    random_state=42) #80% para entrenar y 20% para evaluar el mmodelo  #par√°metros // 42 es random al azar valor predeterminado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5L1GE5zDtrtH"
      },
      "outputs": [],
      "source": [
        "# Inicializo el modelo con la metrica del error absoluto, el modelo queda en regresor\n",
        "regresor = RandomForestRegressor(criterion='absolute_error', random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Elimino aquellas variables que no quiero incluir en el modelo y las guardo en x.\n",
        "# Keep x as a pandas DataFrame to perform one-hot encoding\n",
        "x = students.drop(['math score', 'reading score', 'writing score', 'puntaje_final'],\n",
        "                  axis=1)\n",
        "\n",
        "lista_atributos = x.columns\n",
        "\n",
        "# Ahora selecciono las etiquetas y las guardo en y.\n",
        "y = students['puntaje_final']\n",
        "\n",
        "# Apply one-hot encoding to categorical columns in x\n",
        "x = pd.get_dummies(x, drop_first=True) # drop_first=True avoids multicollinearity\n",
        "\n",
        "# Now convert to numpy arrays for sklearn compatibility\n",
        "x, y = np.array(x), np.array(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Update lista_atributos to reflect the new columns after one-hot encoding\n",
        "# This is important for the feature_importance function later\n",
        "lista_atributos = [col for col in range(X_train.shape[1])] # Use column indices for now\n"
      ],
      "metadata": {
        "id": "EH8_TkMxf4_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1HE79HntrtH"
      },
      "outputs": [],
      "source": [
        "# Entreno el modelo con el 80% de todos mis datos\n",
        "regresor.fit(X_train, y_train);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pQdilCwtrtH"
      },
      "outputs": [],
      "source": [
        "regresor.get_params() #Con que par√°metros estoy corriendo mi modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRnG61KltrtH"
      },
      "source": [
        "Ahora evaluaremos el modelo. Primero, hacemos predicciones para el set de evaluaci√≥n y luego lo comparamos con los valores reales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "od_0uGDKtrtH"
      },
      "outputs": [],
      "source": [
        "# Predigo los valores para el set de testeo, tengo el 20% de las variables y quiero ver en X_test\n",
        "y_pred = regresor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBJlPxRctrtH"
      },
      "outputs": [],
      "source": [
        "# Calculo el error medio absoluto\n",
        "mean_absolute_error(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2cJAcGGtrtI"
      },
      "outputs": [],
      "source": [
        "# Calculo el error porcentual medio promedio\n",
        "np.mean((np.abs(y_pred - y_test)/y_test)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_3atrJ_trtI"
      },
      "outputs": [],
      "source": [
        "# Predigo los valores para el set de training\n",
        "y_pred_train = regresor.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e48sjFHAtrtI"
      },
      "outputs": [],
      "source": [
        "mean_absolute_error(y_train, y_pred_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(y_train)"
      ],
      "metadata": {
        "id": "PU4zb-JjgKB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:5]"
      ],
      "metadata": {
        "id": "bMG_29D6gQ78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train[:5]"
      ],
      "metadata": {
        "id": "w_AV3CNJgZa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61cgp-oGtrtI"
      },
      "outputs": [],
      "source": [
        "# Calculo el error porcentual medio promedio para el entrenamiento\n",
        "np.mean((np.abs(y_train - y_pred_train)/y_train)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHnMaULytrtI"
      },
      "source": [
        "Obtenemos la importancia de cada feature usando `feature_importances_`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6XSCBojtrtI"
      },
      "outputs": [],
      "source": [
        "for x, y in list(zip(lista_atributos,regresor.feature_importances_)):\n",
        "    print(f'Atributo: {x}, Importancia: {y}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RPXEAERtrtJ"
      },
      "source": [
        "**¬øPodemos aceptar un modelo que prediga con un 20% de error?** ¬øQu√© podemos hacer ahora para mejorar nuestro modelo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1l5y2H0trtK"
      },
      "source": [
        "De manera de hacer una b√∫squeda, utilizaremos la funci√≥n [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdipS65PtrtJ"
      },
      "source": [
        "Recordemos que utilizamos un algoritmo de regresi√≥n, por lo tanto, vamos a usar los error para poder evaluar el desempe√±o de nuestro modelo. Primero creemos unas funciones que nos permitiran obtener los errores facilmente y graficar los resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-BvioqAtrtJ"
      },
      "outputs": [],
      "source": [
        "def evaluation(y_test, predictions):\n",
        "\n",
        "    # Calcula mae\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    #calculate mape\n",
        "    mape = np.mean((np.abs(y_test - predictions)/y_test)*100)\n",
        "    #print calculated values\n",
        "    print(f\"El error absoluto medio para el modelo es {round(mae, 2)}\")\n",
        "    print(f\"El error porcentual absoluto medio para el modelo es {round(mape, 2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqamgIKstrtJ"
      },
      "outputs": [],
      "source": [
        "def graph_real_pred(y_test, predictions, color):\n",
        "    \"\"\"\n",
        "    Funcion que grafica los valores reales vs. predichos\n",
        "    :param y_test: valores reales\n",
        "    :param predictions: valores predichos\n",
        "    :param color: color para el plot.\n",
        "\n",
        "    :return: Scatterplot mostrando la relacion entre el valor real y el predicho\n",
        "    \"\"\"\n",
        "    plt.scatter(y_test, predictions, c=color, s=10)\n",
        "    plt.gca().spines['top'].set_visible(False)\n",
        "    plt.gca().spines['bottom'].set_visible(False)\n",
        "    plt.gca().spines['left'].set_visible(False)\n",
        "    plt.gca().spines['right'].set_visible(False)\n",
        "    plt.xlabel('Real', size=15, labelpad=1)\n",
        "    plt.ylabel('Predicted', size=15, labelpad=1)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77wu4Y6ttrtJ"
      },
      "outputs": [],
      "source": [
        "def feature_importance(model, feature_list):\n",
        "    \"\"\"\n",
        "    Function that gets and plots the feature importance\n",
        "    for the given model\n",
        "    :param model: the model to evaluaate\n",
        "    :param feature_list: a list of features contained in the model\n",
        "\n",
        "    :returns a plot with feature importance\n",
        "    \"\"\"\n",
        "    # Obtiene la lista de importancias\n",
        "    importances = list(model.feature_importances_)\n",
        "    # Junta los nombres de los atributos y las importancias\n",
        "    feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
        "    # Ordena por orden de importancia\n",
        "    feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
        "    # Print la lista de importancias\n",
        "    [print('Variable: {} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
        "    # Colores\n",
        "    colors = cm.rainbow(np.linspace(0, 1, len(feature_list)))\n",
        "\n",
        "    # Caracteristicas en orden de importancia\n",
        "    characteristics = [x[0] for x in feature_importances]\n",
        "    # Obtiene las importancias\n",
        "    importances_plot = [x[1] for x in feature_importances]\n",
        "    # Grafica un bar plot\n",
        "    plt.bar(characteristics, importances_plot, color=colors)\n",
        "    # Personalizamos el grafico\n",
        "    plt.xticks(list(range(len(characteristics))), characteristics, rotation = 90)\n",
        "    plt.gca().spines['top'].set_visible(False)\n",
        "    plt.gca().spines['bottom'].set_visible(False)\n",
        "    plt.gca().spines['left'].set_visible(False)\n",
        "    plt.gca().spines['right'].set_visible(False)\n",
        "    plt.gcf().subplots_adjust(bottom=0.3);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T72rl1yytrtK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIMcNdG9trtK"
      },
      "outputs": [],
      "source": [
        "# Valores para los parametros a optimizar\n",
        "param_grid_rf = {\n",
        "    'criterion': ['absolute_error'],\n",
        "    'n_estimators': [70, 80, 90, 100, 120],\n",
        "    'max_features': ['log2','sqrt'],\n",
        "    'max_depth': [1, 3, 5, 10, 20, 50],\n",
        "    'min_samples_leaf': [1, 3, 5, 10, 20, 50]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jc56nSwtrtK"
      },
      "source": [
        "```python\n",
        "\n",
        "*   Elemento de la lista\n",
        "*   Elemento de la lista\n",
        "\n",
        "\n",
        "modelo 1: mae, 70, log2, 1, 1 --> CV=5 #cuanto grupos voy a armar (4 los va a probar y 1 lo va a guardar)\n",
        "modelo 2: mae, 80, log2, 1, 1\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoVfHWpntrtK"
      },
      "outputs": [],
      "source": [
        "# Inicializamos un modelo\n",
        "grid_regresor = RandomForestRegressor(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVXc7XzjtrtK"
      },
      "outputs": [],
      "source": [
        "# Creamos la busqueda\n",
        "rf_search = GridSearchCV(estimator=grid_regresor, param_grid=param_grid_rf,\n",
        "                         cv=5, scoring='neg_mean_absolute_error', verbose=2, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4R2pZ9ytrtL"
      },
      "outputs": [],
      "source": [
        "# Corremos el gridsearch con una validaci√≥n usando 3 folds.\n",
        "rf_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQVKYKpDtrtL"
      },
      "source": [
        "**¬øCu√°l es nuestro mejor estimador?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvsVsxNntrtL"
      },
      "outputs": [],
      "source": [
        "rf_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjYGh8PMtrtL"
      },
      "outputs": [],
      "source": [
        "rf_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvNmbXcztrtL"
      },
      "outputs": [],
      "source": [
        "rf_search.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rEBVnT_Glwh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b69YREF_trtL"
      },
      "outputs": [],
      "source": [
        "# Asignamos el mejor estimador a mejor_regresor\n",
        "mejor_regresor = RandomForestRegressor(criterion='absolute_error', n_estimators=70, max_depth=10, max_features='log2', min_samples_leaf=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZmCj0tltrtL"
      },
      "outputs": [],
      "source": [
        "# Entrenamos el modelo\n",
        "mejor_regresor.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ib-JR31dtrtM"
      },
      "outputs": [],
      "source": [
        "# Hacemos la prediccion para el test de evaluaci√≥n\n",
        "predicciones = mejor_regresor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ikp4hPstrtM"
      },
      "outputs": [],
      "source": [
        "# Error\n",
        "evaluation(y_test, predicciones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShDDZrpXtrtM"
      },
      "outputs": [],
      "source": [
        "# Correlacion\n",
        "graph_real_pred(y_test, predicciones, color='#E67E22')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWm0ud5-trtM"
      },
      "outputs": [],
      "source": [
        "# Importancia de cada feature\n",
        "feature_importance(mejor_regresor, lista_atributos)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluacion de un modelo de Clasificaci√≥n"
      ],
      "metadata": {
        "id": "uqRlN187COSX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gc8xM-O_uC1I"
      },
      "outputs": [],
      "source": [
        "# metricas\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "students['aprobado'] = students['puntaje_final'].apply(lambda x: 0 if x < 60 else 1)"
      ],
      "metadata": {
        "id": "NpUJb0VcCNUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSGiAQjtuC1H"
      },
      "outputs": [],
      "source": [
        "xc = students.drop(['math score', 'reading score', 'writing score', 'puntaje_final', 'aprobado'],\n",
        "                  axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJRPvl2OuC1H"
      },
      "outputs": [],
      "source": [
        "yc = students['aprobado']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply one-hot encoding to categorical columns in xc\n",
        "# drop_first=True avoids multicollinearity\n",
        "xc = pd.get_dummies(xc, drop_first=True)"
      ],
      "metadata": {
        "id": "wjd1sxTVmbiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwvMJhn6uC1H"
      },
      "outputs": [],
      "source": [
        "xc, yc = np.array(xc), np.array(yc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(xc, yc, test_size=0.2,\n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "mXBt1YyUCZNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR417dgBuC1I"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGc1a-1luC1I"
      },
      "outputs": [],
      "source": [
        "# Entrenamos el modelo\n",
        "knn.fit(X_train_c, y_train_c);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0M8J3wRbuC1I"
      },
      "outputs": [],
      "source": [
        "# Predecimos\n",
        "predicciones_cla = knn.predict(X_test_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0LxAQBmuC1I"
      },
      "outputs": [],
      "source": [
        "predicciones_train = knn.predict(X_train_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6Uwma9GuC1I"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_train_c, predicciones_train)*100\n",
        "print(f'{round(accuracy, 2)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vRO4QDfuC1J"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_test_c, predicciones_cla)*100\n",
        "print(f'{round(accuracy, 2)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XL2SXFGuC1L"
      },
      "source": [
        "**Metricas**\n",
        "\n",
        "Matriz de confusi√≥n:\n",
        "\n",
        "True Negative (TN)  |  False positive (FP)   \n",
        "= = = = = = = = = = = = = = = = = = = = =       \n",
        "False negative (FN) | True positive (TP)  \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cgHpEaAZPJnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asignamos el mejor estimador a knn_best\n",
        "knn_best = vecinos_search.best_estimator_\n"
      ],
      "metadata": {
        "id": "axnFJLw0oAWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asigna las predicciones del mejor clasificador KNN a new_predictions\n",
        "# Esto se hace DESPU√âS de correr el GridSearchCV y obtener knn_best\n",
        "new_predictions = knn_best.predict(X_test_c)"
      ],
      "metadata": {
        "id": "MD_56cMsm9ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfIuQbrXuC1L"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "random_confusion = confusion_matrix(y_test_c, new_predictions)\n",
        "sns.heatmap(random_confusion, cmap=\"YlGnBu\",annot=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wR0NCmkuC1M"
      },
      "outputs": [],
      "source": [
        "print(f\"Accuracy: {accuracy_score(y_test_c, predicciones_cla)*100 :.2f}%\")\n",
        "print(f\"Precision: {precision_score(y_test_c, predicciones_cla)*100 :.2f}%\")\n",
        "print(f\"Recall: {recall_score(y_test_c, predicciones_cla)*100 :.2f}%\")\n",
        "print(f\"F1 score: {f1_score(y_test_c, predicciones_cla)*100 :.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Buscando el 'mejor' modelo (Clasificaci√≥n)"
      ],
      "metadata": {
        "id": "VFwTV6DcCxnS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34sDKv4iuC1J"
      },
      "source": [
        "Ahora vamos a optimizar los parameteros del clasificador kNN. Para eso podemos revisar en la documentaci√≥n que parametros se pueden [optimizar](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18mmPTSLuC1J"
      },
      "source": [
        "Vamos a buscar el mejor k:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l80u1M-SuC1J"
      },
      "outputs": [],
      "source": [
        "####\n",
        "ACC_train = []\n",
        "ACC_test = []\n",
        "vecinos = [1, 3, 5, 10, 15, 20, 25, 30]\n",
        "for n in vecinos:\n",
        "    clf = KNeighborsClassifier(n_neighbors=n)\n",
        "    clf.fit(X_train_c, y_train_c)\n",
        "    y_train_pred = clf.predict(X_train_c)\n",
        "    train_acc = accuracy_score(y_train_c, y_train_pred)\n",
        "    ACC_train.append(train_acc)\n",
        "    y_test_pred = clf.predict(X_test_c)\n",
        "    test_acc = accuracy_score(y_test_c, y_test_pred)\n",
        "    ACC_test.append(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tLr91aHuC1J"
      },
      "outputs": [],
      "source": [
        "plt.plot(vecinos,ACC_train,'o-',label='train', color='#DCE775')\n",
        "plt.plot(vecinos,ACC_test,'o-',label='test', color='#EC407A')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qz9GFTKGuC1K"
      },
      "outputs": [],
      "source": [
        "# Valores para los parametros a optimizar\n",
        "param_grid_vec = {\n",
        "    'n_neighbors': [18, 20, 22],\n",
        "    'weights': ['uniform','distance'],\n",
        "    'metric': ['euclidean', 'manhattan'],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYiIXlcAuC1K"
      },
      "outputs": [],
      "source": [
        "knn_search = KNeighborsClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBtzR4CFuC1K"
      },
      "outputs": [],
      "source": [
        "vecinos_search = GridSearchCV(estimator=knn_search, param_grid=param_grid_vec,\n",
        "                         cv=3, verbose=2, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Uf8RGNKuC1K"
      },
      "outputs": [],
      "source": [
        "vecinos_search.fit(X_train_c, y_train_c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ3gruc4uC1K"
      },
      "source": [
        "**¬øCu√°l es nuestro mejor estimador?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z3kKFnLuC1K"
      },
      "outputs": [],
      "source": [
        "vecinos_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt6T6aozuC1L"
      },
      "outputs": [],
      "source": [
        "vecinos_search.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nK9qHxmyuC1L"
      },
      "outputs": [],
      "source": [
        "knn_best = vecinos_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7itI4OsuC1L"
      },
      "outputs": [],
      "source": [
        "knn_best.fit(X_train_c, y_train_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkLAnDQZuC1L"
      },
      "outputs": [],
      "source": [
        "new_predictions = knn_best.predict(X_test_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zwu0I4IEC5Ed"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "random_confusion = confusion_matrix(y_test_c, new_predictions)\n",
        "sns.heatmap(random_confusion, cmap=\"YlGnBu\",annot=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2thRbqSpC5Ed"
      },
      "outputs": [],
      "source": [
        "print(f\"Accuracy: {accuracy_score(y_test_c, new_predictions)*100 :.2f}%\")\n",
        "print(f\"Precision: {precision_score(y_test_c, new_predictions)*100 :.2f}%\")\n",
        "print(f\"Recall: {recall_score(y_test_c, new_predictions)*100 :.2f}%\")\n",
        "print(f\"F1 score: {f1_score(y_test_c, new_predictions)*100 :.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5yG_c4wURYj1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}